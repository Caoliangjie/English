\documentclass[10pt,twocolumn,letterpaper]{article}
\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{url}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[breaklinks=true,bookmarks=false,backref=page]{hyperref}
\cvprfinalcopy
\def\cvprPaperID{****}
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}
\begin{document}
\title{\textbf{Spherical CNNS
}}
\author{Liangjie Cao\\\\ July 14, 2018}
\maketitle
\section{GAN}
  \begin{figure}[!htb]
  	\centering
  	\includegraphics[width=3in]{framwork.png}\\
  	\caption{High-level view of the GAN framework. The generator produces synthetic images. The
  		discriminator takes images as input and outputs the probability it assigns to the image of being
  		real. A common analogy is that of an art forger (the generator) which tries to forge paintings and
  		an art investigator (the discriminator) which tries to detect imitations}\label{Figure2} 
  \end{figure}
The GAN framework we have learned yesterday is can be seen from Figure~\ref{Figure2}. The easiest way to define and analyse the game is as a zero-sum game where $D_\omega$ and
$G_\theta$ are the strategies of the two players. Such a game can be described by a value function
$V (D, G)$ which in this case represents the payoff of the discriminator. The discriminator
wants to maximise $V$ while the generator wishes to minimise it. The payoff described by
$V$ must be proportional to the ability of $D$ to distinguish between real and fake samples. The value function from Equation~\ref{eq1} which was originally proposed in~\cite{name5} comes as a
natural choice.
\begin{equation}
V(D,G)=\mathbb{E}_{X~\mathbb{P}_r}[log(D(x))]+\mathbb{E}_{Z~P_z}[log(1-D(G(Z))]
\label{eq1}
\end{equation}
\par On the one hand, note that $V (D, G)$ becomes higher when the discriminator can distinguish between real and fake samples. On the other hand, $V$ becomes lower when the
generator is performing well, and the critic cannot distinguish well between real and fake samples.
\par The difference from maximum likelihood models is that samples generated by the generator have an implicit distribution $\mathbb{P}_g$ determined by the particular value of $\theta$. $\mathbb{P}_g$ cannot be explicitly evaluated. The discriminator forces the generator to bring $\mathbb{P}_g$ close to $\mathbb{P}_r$.
\par Zero-sum games are minimax games so the optimal parameters of the generator can be described as in Equation~\ref{eq2}.
\begin{equation}
\theta^{*}=\arg\min_{\theta}\max_{\omega}V(D,G)
\label{eq2}
\end{equation}
  \begin{figure}[!htb]
  	\centering
  	\includegraphics[width=3in]{fag.png}\\
  	\caption{The Nash Equilibrium corresponds to a saddle point in space where $V$ is at a minimum
  		with respect to $\theta$ and at a maximum with respect to $\omega$. Neither of the networks has any interest
  		to change their parameters}\label{Figure3} 
  \end{figure}
The solution of the minimax optimisation is a Nash Equilibrium (Figure~\ref{Figure3}). Theorem~\footnote{\paragraph{Theorem1}\label{key}$The Nash equilibrium of the (non-parametric) GAN game occurs when:$
	\par$1. The strategy of the discriminator is$ $D =\frac{\mathbb{P}_r}{\mathbb{P}_r+\mathbb{P}_g}$
	\par$2. The strategy$ $G$ of the generator makes $\mathbb{P}_g= \mathbb{P}_r$.} describes the exciting properties of the equilibrium for non-parametric functions.
The theorem confirms the intuition that as the two players play this game, the generator will improve at producing realistic samples.
\par In practice, the generator does not minimise $V(D,G)$. This would be equivalent to minimising $E_{Z∼pZ}[log(1 −D_{\omega}(G_{\theta}(z)))]$, but the function $log(1 − D_{\omega}(G_{\theta}(z)))$ has saturating gradient when the discriminator is performing well and the function approaches
log(1). This makes it difficult for the generator to improve when it is not performing well. Instead, the generator is minimising $L_G$ from~\ref{eq3} whose gradient saturates only when the generator is already performing well. The loss $L_D$ of the critic is included in~\ref{eq4}.
\begin{equation}
L_G=-\mathbb{E}_{z~pz}[log(D_\omega(G_\theta(z)))]
\label{eq3}
\end{equation}
\begin{equation}
\begin{split}
L_D=-mathbb{E}_{x~pr}[log(D_\omega(x))]
\\
-\mathbb{E}_{z~pz}[log(1-D_\omega(G_\theta(z)))]
\end{split}
\label{eq4}
\end{equation}
\section{Conditional Generative Adversarial Networks}
The original GAN paper~\cite{name5} describes how one can trivially turn GANs into a conditional generative model. To generate data conditioned on some condition vector $c$, $c$ is appended to both the generator and the discriminator in any of their layers. The networks will learn to adapt and adjust their parameters to these additional inputs.
  \begin{figure}[!htb]
  	\centering
  	\includegraphics[width=3in]{gan2.png}\\
  	\caption{Probabilistic graphical model view of regular GANs (left) and conditional GANs (right)}\label{Figure2} 
  \end{figure}
  \par Conditional GANs can also be seen from the perspective of a probabilistic graphical
  model (Figure~\ref{Figure2}). In the case of regular GANs, the noise $Z$ influences the observable $X$.
  For conditional GAN $s$, both $Z$ and $C$ influence $X$. In the particular case of text to image
  synthesis, the states $c$ of $C$ are vectors encoding a text description.
\bibliographystyle{abbrv}
\bibliography{yinyong10}
\end{document}