\documentclass[25pt]{article}
\usepackage{ctex}
\usepackage{CJK}
\usepackage{picinpar,graphicx}
\usepackage{cite}
\usepackage{multirow}
\usepackage{hyperref,amsmath,amssymb,amscd}
\setlength{\parindent}{2em}
\twocolumn
\begin{document}
\title{\textbf{Backpropagation I}}
\author{\textbf{Liangjie Cao}}
\date{\textbf{5 May 2018}}
\maketitle
\par
\textbf{Today I learn the process of Backpropagation to train multilayer architectures. The key insight is that the derivative (or gradient) of the objective with respect to the input of a module can be computed by working backwards from the gradient with respect to the output of that module (or the input of the subsequent module) in Fig. 1.\ref{Figure}}\\
\par
\textbf{In the late 1990s, neural nets and backpropagation were largely forsaken by the machine-learning community and ignored by the computer vision and speech recognition communities. It was widely thought that learning useful, multistage, feature extractors with little prior knowledge was infeasible. In particular, it was commonly thought that simple gradient descent would get trapped in poor local minima — weight configurations for which no small change would reduce the average error. \cite{name1}And the paper says that is not a simple probelm.}
\\
\par
\textbf{Then around 2006, cifar brought together researchers and renewed interest in deep feedforward neural networks. Researchers propose an unsupervised learning\ref{Table} approach that creates network layers to detect features without using tagged data. These network layers can be used to reconstruct or model the activity of feature detectors. Through the pre-training process. The weights of the deep network can be initialized to interesting values. An output layer is then added to the top of the network and fine-tuned using standard back propagation algorithms. I will continue learning in the following days.}\\
\onecolumn
\begin{table}[!htbp]
  \centering
 \begin{tabular}{|p{3cm}|p{3cm}|p{3cm}}
   \hline
     1 & Cluster ( e. g., hybrid models )\\
  \hline
     2 & , hierarchical cluster\\
   \hline
  \end{tabular}
  \caption{\textbf{Classifition of unsupervised learning}} \label{Table}
  \end{table}
 \begin{figure}[ht]
 \centering
 \includegraphics[width=15cm]{network.png}\\
 \caption{\textbf{ Multilayer neural networks and backpropagation.}}\label{Figure}
\end{figure}
\bibliographystyle{plain}
\bibliography{yinyong1}
\end{document}

